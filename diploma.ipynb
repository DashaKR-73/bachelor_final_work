{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6175e05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "\n",
    "# Precision/Recall @ Threshold\n",
    "def precision_recall_at_k(y_true, scores, threshold=0.95):\n",
    "    y_pred = (scores >= threshold).astype(int)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    return precision, recall, y_pred\n",
    "\n",
    "# –¢–µ–æ—Ä–µ—Ç–∏—á–Ω–∏–π –æ–ø–∏—Å –º–æ–¥–µ–ª–µ–π\n",
    "MODEL_DESCRIPTIONS = {\n",
    "    \"Isolation Forest\": \"Isolation Forest: –±—É–¥—É—î –ª—ñ—Å –≤–∏–ø–∞–¥–∫–æ–≤–∏—Ö –¥–µ—Ä–µ–≤ —ñ –≤–∏–¥—ñ–ª—è—î –∞–Ω–æ–º–∞–ª—ñ—ó –∑–∞ –≥–ª–∏–±–∏–Ω–æ—é —ñ–∑–æ–ª—è—Ü—ñ—ó.\",\n",
    "    \"Autoencoder\": \"Autoencoder: –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂–∞, —è–∫–∞ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É—é—î –≤—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ; –∞–Ω–æ–º–∞–ª—ñ—ó –º–∞—é—Ç—å –≤–∏—Å–æ–∫—É reconstruction error.\",\n",
    "    \"One-Class SVM\": \"One-Class SVM: –≤—á–∏—Ç—å –º–µ–∂—É –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö, –∞–Ω–æ–º–∞–ª—ñ—ó ‚Äì –ø–æ–∑–∞ —Ü—ñ—î—é –º–µ–∂–µ—é (–Ω–∞ –ø—ñ–¥–≤–∏–±—ñ—Ä—Ü—ñ –¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ).\",\n",
    "    \"LOF\": \"Local Outlier Factor: –æ—Ü—ñ–Ω—é—î –∞–Ω–æ–º–∞–ª—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ª–æ–∫–∞–ª—å–Ω–æ—ó —â—ñ–ª—å–Ω–æ—Å—Ç—ñ —Å—É—Å—ñ–¥—ñ–≤ (–Ω–∞ –ø—ñ–¥–≤–∏–±—ñ—Ä—Ü—ñ –¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ).\"\n",
    "}\n",
    "\n",
    "# –õ–æ–≥—É–≤–∞–Ω–Ω—è\n",
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.logs = []\n",
    "\n",
    "    def log(self, method, transaction_idx, score, reason=\"\"):\n",
    "        self.logs.append({\n",
    "            \"method\": method,\n",
    "            \"transaction_idx\": transaction_idx,\n",
    "            \"score\": score,\n",
    "            \"reason\": reason\n",
    "        })\n",
    "\n",
    "    def get_logs(self):\n",
    "        return pd.DataFrame(self.logs)\n",
    "\n",
    "logger = Logger()\n",
    "\n",
    "# Fraud Detector\n",
    "class FraudDetector:\n",
    "    def __init__(self, df, progress_callback=None, threshold=0.95, batch_size=5000):\n",
    "        self.df = df.copy()\n",
    "        self.progress_callback = progress_callback\n",
    "        self.threshold = threshold\n",
    "        self.batch_size = batch_size\n",
    "        self.y = df[\"Class\"].values if \"Class\" in df.columns else None\n",
    "\n",
    "        self.features = [f\"V{i}\" for i in range(1,29)] + ['Amount']\n",
    "        self.X = self.df[self.features].values\n",
    "\n",
    "        # –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_scaled = self.scaler.fit_transform(self.X)\n",
    "\n",
    "        # –û–±—Ä–æ–±–∫–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å—É (oversampling)\n",
    "        if self.y is not None and np.mean(self.y) < 0.05:\n",
    "            smote = SMOTE(sampling_strategy=0.1, random_state=42)\n",
    "            self.X_scaled, self.y = smote.fit_resample(self.X_scaled, self.y)\n",
    "\n",
    "    # Isolation Forest\n",
    "    def isolation_forest(self):\n",
    "        model = IsolationForest(n_estimators=200, contamination=0.01, random_state=42)\n",
    "        model.fit(self.X_scaled)\n",
    "        scores = -model.score_samples(self.X_scaled)\n",
    "        scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "        if self.progress_callback:\n",
    "            self.progress_callback(100)\n",
    "\n",
    "        top_idx = np.argsort(scores)[::-1][:5]\n",
    "        for i in top_idx:\n",
    "            logger.log(\"Isolation Forest\", i, scores[i], reason=\"High anomaly score\")\n",
    "        return scores, self.y\n",
    "\n",
    "    # Autoencoder\n",
    "    def autoencoder(self):\n",
    "        X_tensor = torch.tensor(self.X_scaled, dtype=torch.float32)\n",
    "        dataset = TensorDataset(X_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "        class AutoEncoder(nn.Module):\n",
    "            def __init__(self, input_dim):\n",
    "                super().__init__()\n",
    "                self.encoder = nn.Sequential(nn.Linear(input_dim, 32), nn.ReLU(), nn.Linear(32, 8))\n",
    "                self.decoder = nn.Sequential(nn.Linear(8, 32), nn.ReLU(), nn.Linear(32, input_dim))\n",
    "            def forward(self, x):\n",
    "                return self.decoder(self.encoder(x))\n",
    "\n",
    "        model = AutoEncoder(X_tensor.shape[1])\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "        epochs = 10\n",
    "        total_steps = epochs * len(loader)\n",
    "        step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for (batch,) in loader:\n",
    "                optimizer.zero_grad()\n",
    "                recon = model(batch)\n",
    "                loss = criterion(recon, batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                step += 1\n",
    "                if self.progress_callback:\n",
    "                    self.progress_callback(int(step/total_steps*100))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            recon_all = model(X_tensor)\n",
    "            scores = torch.mean((X_tensor - recon_all) ** 2, dim=1).numpy()\n",
    "            scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "\n",
    "        top_idx = np.argsort(scores)[::-1][:5]\n",
    "        for i in top_idx:\n",
    "            logger.log(\"Autoencoder\", i, scores[i], reason=\"High reconstruction error\")\n",
    "\n",
    "        if self.progress_callback:\n",
    "            self.progress_callback(100)\n",
    "        return scores, self.y\n",
    "\n",
    "    # One-Class SVM (subsample)\n",
    "    def one_class_svm(self):\n",
    "        subsample_size = min(20000, len(self.X_scaled))\n",
    "        idx = np.random.choice(len(self.X_scaled), subsample_size, replace=False)\n",
    "        X_sub = self.X_scaled[idx]\n",
    "\n",
    "        model = OneClassSVM(nu=0.01, kernel='rbf', gamma='scale')\n",
    "        model.fit(X_sub)\n",
    "\n",
    "        scores = np.zeros(len(self.X_scaled))\n",
    "        for start in range(0, len(self.X_scaled), self.batch_size):\n",
    "            end = start + self.batch_size\n",
    "            batch = self.X_scaled[start:end]\n",
    "            scores[start:end] = -model.decision_function(batch)\n",
    "            if self.progress_callback:\n",
    "                self.progress_callback(int(end/len(self.X_scaled)*100))\n",
    "\n",
    "        scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "        top_idx = np.argsort(scores)[::-1][:5]\n",
    "        for i in top_idx:\n",
    "            logger.log(\"One-Class SVM\", i, scores[i], reason=\"High anomaly score\")\n",
    "        return scores, self.y\n",
    "\n",
    "    # LOF (subsample)\n",
    "    def lof(self):\n",
    "        subsample_size = min(20000, len(self.X_scaled))\n",
    "        idx = np.random.choice(len(self.X_scaled), subsample_size, replace=False)\n",
    "        X_sub = self.X_scaled[idx]\n",
    "\n",
    "        model = LocalOutlierFactor(n_neighbors=20, novelty=True)\n",
    "        model.fit(X_sub)\n",
    "\n",
    "        scores = np.zeros(len(self.X_scaled))\n",
    "        for start in range(0, len(self.X_scaled), self.batch_size):\n",
    "            end = start + self.batch_size\n",
    "            batch = self.X_scaled[start:end]\n",
    "            scores[start:end] = -model.decision_function(batch)\n",
    "            if self.progress_callback:\n",
    "                self.progress_callback(int(end/len(self.X_scaled)*100))\n",
    "\n",
    "        scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "        top_idx = np.argsort(scores)[::-1][:5]\n",
    "        for i in top_idx:\n",
    "            logger.log(\"LOF\", i, scores[i], reason=\"High anomaly score\")\n",
    "        return scores, self.y\n",
    "\n",
    "# GUI\n",
    "class App:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        root.title(\"–°–∏—Å—Ç–µ–º–∞ –≤–∏—è–≤–ª–µ–Ω–Ω—è —à–∞—Ö—Ä–∞–π—Å—å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ–π\")\n",
    "        root.geometry(\"900x800\")\n",
    "\n",
    "        self.df = None\n",
    "\n",
    "        tk.Button(root, text=\"üìÇ –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ CSV-—Ñ–∞–π–ª\", command=self.load_csv).pack(pady=5)\n",
    "\n",
    "        self.method = ttk.Combobox(\n",
    "            root, values=[\"Isolation Forest\",\"Autoencoder\",\"One-Class SVM\",\"LOF\"],\n",
    "            state=\"readonly\", width=30)\n",
    "        self.method.set(\"Isolation Forest\")\n",
    "        self.method.pack(pady=5)\n",
    "\n",
    "        tk.Button(root, text=\"‚ñ∂ –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –∞–Ω–∞–ª—ñ–∑\", command=self.run).pack(pady=5)\n",
    "\n",
    "        self.progress = ttk.Progressbar(root, orient='horizontal', length=600, mode='determinate')\n",
    "        self.progress.pack(pady=5)\n",
    "\n",
    "        tk.Label(root, text=\"Threshold (–¥–ª—è –∞–ª–µ—Ä—Ç—ñ–≤, 0-1)\").pack()\n",
    "        self.threshold_var = tk.DoubleVar(value=0.95)\n",
    "        tk.Entry(root, textvariable=self.threshold_var, width=10).pack()\n",
    "\n",
    "        self.output = tk.Text(root, height=15, width=105)\n",
    "        self.output.pack(pady=5)\n",
    "\n",
    "        self.figure_frame = tk.Frame(root)\n",
    "        self.figure_frame.pack(fill='both', expand=True)\n",
    "\n",
    "    def load_csv(self):\n",
    "        path = filedialog.askopenfilename(filetypes=[(\"CSV —Ñ–∞–π–ª–∏\",\"*.csv\")])\n",
    "        if path:\n",
    "            self.df = pd.read_csv(path)\n",
    "            messagebox.showinfo(\"–ì–æ—Ç–æ–≤–æ\", \"–î–∞—Ç–∞—Å–µ—Ç —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ\")\n",
    "\n",
    "    def update_progress(self, value):\n",
    "        self.progress['value'] = value\n",
    "        self.root.update_idletasks()\n",
    "\n",
    "    def run(self):\n",
    "        if self.df is None:\n",
    "            messagebox.showerror(\"–ü–æ–º–∏–ª–∫–∞\", \"–°–ø–æ—á–∞—Ç–∫—É –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç\")\n",
    "            return\n",
    "\n",
    "        threshold = self.threshold_var.get()\n",
    "        detector = FraudDetector(self.df, progress_callback=self.update_progress, threshold=threshold)\n",
    "\n",
    "        model_name = self.method.get()\n",
    "        self.output.delete(\"1.0\", tk.END)\n",
    "        self.output.insert(tk.END, f\"–ú–æ–¥–µ–ª—å: {model_name}\\n\")\n",
    "        self.output.insert(tk.END, f\"–û–ø–∏—Å: {MODEL_DESCRIPTIONS.get(model_name,'')}\\n\\n\")\n",
    "\n",
    "        if model_name == \"Isolation Forest\":\n",
    "            scores, y_true = detector.isolation_forest()\n",
    "        elif model_name == \"Autoencoder\":\n",
    "            scores, y_true = detector.autoencoder()\n",
    "        elif model_name == \"One-Class SVM\":\n",
    "            scores, y_true = detector.one_class_svm()\n",
    "        elif model_name == \"LOF\":\n",
    "            scores, y_true = detector.lof()\n",
    "\n",
    "        # Precision/Recall\n",
    "        p, r, y_pred = precision_recall_at_k(y_true, scores, threshold=threshold)\n",
    "        self.output.insert(tk.END, f\"Threshold: {threshold:.2f}\\n\")\n",
    "        self.output.insert(tk.END, f\"Precision: {p:.4f}\\nRecall: {r:.4f}\\n\")\n",
    "        self.output.insert(tk.END, f\"Top-–ø—ñ–¥–æ–∑—Ä—ñ–ª—ñ —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ—ó: {np.sum(y_pred)}\\n\")\n",
    "\n",
    "        # –ì—Ä–∞—Ñ—ñ–∫ score\n",
    "        for widget in self.figure_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8,5))\n",
    "        ax.hist(scores[y_true==0], bins=60, alpha=0.6, label=\"–ù–æ—Ä–º–∞–ª—å–Ω—ñ\")\n",
    "        ax.hist(scores[y_true==1], bins=60, alpha=0.9, label=\"–®–∞—Ö—Ä–∞–π—Å—å–∫—ñ\")\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.set_title(f\"–ê–Ω–æ–º–∞–ª—ñ–π–Ω–∏–π —Å–∫–æ—Ä ({model_name})\")\n",
    "        ax.set_xlabel(\"Score\")\n",
    "        ax.set_ylabel(\"–ö—ñ–ª—å–∫—ñ—Å—Ç—å (–ª–æ–≥)\")\n",
    "        ax.legend()\n",
    "        fig.tight_layout()\n",
    "\n",
    "        canvas = FigureCanvasTkAgg(fig, master=self.figure_frame)\n",
    "        canvas.draw()\n",
    "        canvas.get_tk_widget().pack(fill='both', expand=True)\n",
    "\n",
    "        # –í–∏–≤—ñ–¥ –ª–æ–≥—ñ–≤ —Ç–æ–ø-5\n",
    "        self.output.insert(tk.END, \"\\n–õ–æ–≥ —Ç–æ–ø-5 –ø—ñ–¥–æ–∑—Ä—ñ–ª–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ–π (–∑–∞ —ñ–Ω–¥–µ–∫—Å–æ–º):\\n\")\n",
    "        logs_df = logger.get_logs()\n",
    "        self.output.insert(tk.END, logs_df.head().to_string(index=False))\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ GUI\n",
    "root = tk.Tk()\n",
    "app = App(root)\n",
    "root.mainloop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
